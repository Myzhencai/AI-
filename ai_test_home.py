import re
import subprocess
import time
from pathlib import Path

import streamlit as st
from PIL import Image
import google.generativeai as genai
import docx
import PyPDF2
import pandas as pd
import os
import pypandoc
import tempfile
import json
import jsonpath
import ast
import multiprocessing


# å­è¿›ç¨‹æ‰§è¡Œå‡½æ•°ï¼šå‘é€ promptï¼Œå¹¶ä¿ç•™å†å²
def chat_worker(pipe_conn, model_name, prompt_text, api_key, history, gen_config=None):
    try:
        genai.configure(api_key=api_key)
        chat = genai.GenerativeModel(model_name).start_chat(history=history)
        response = chat.send_message(prompt_text, stream=False, generation_config=gen_config)
        response.resolve()
        pipe_conn.send({
            "text": response.text,
            "history": chat.history
        })
    except Exception as e:
        pipe_conn.send({
            "text": f"é”™è¯¯ï¼š{str(e)}",
            "history": history
        })
    finally:
        pipe_conn.close()

# ä¸»è¿›ç¨‹è°ƒç”¨ï¼šå¸¦è¶…æ—¶ã€å®‰å…¨è¿”å›ç»“æœ+å†å²
def safe_send_message_mp(model_name, prompt, api_key, history, gen_config=None, timeout=30):
    parent_conn, child_conn = multiprocessing.Pipe()
    p = multiprocessing.Process(
        target=chat_worker,
        args=(child_conn, model_name, prompt, api_key, history, gen_config)
    )
    p.start()
    if parent_conn.poll(timeout):
        result = parent_conn.recv()
        p.join()
        return result["text"], result["history"]
    else:
        p.terminate()
        return f"è¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åå†è¯•ã€‚", history

def send_prompt_with_timeout(prompt, timeout=30):
    response_text, updated_history = safe_send_message_mp(
        model_name=st.session_state.model,
        prompt=prompt,
        api_key=st.session_state.google_api_key,
        history=st.session_state.chat_history if "chat_history" in st.session_state else [],
        gen_config=gen_config,
        timeout=timeout
    )
    st.session_state.chat_history = updated_history
    return response_text

def markdown_to_docx_bytes(md_text):
    with tempfile.NamedTemporaryFile(suffix=".docx", delete=False) as tmpfile:
        tmp_path = tmpfile.name
    pypandoc.convert_text(md_text, 'docx', format='md', outputfile=tmp_path)
    with open(tmp_path, 'rb') as f:
        return f.read()


def safe_filename(name: str, default="doc.docx") -> str:
    # åªä¿ç•™å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿ï¼Œé˜²æ­¢æ–‡ä»¶åéæ³•
    safe_name = re.sub(r'[^\w\-_. ]', '', name)
    safe_name = safe_name.strip()
    if not safe_name:
        return default
    if not safe_name.lower().endswith(".docx"):
        safe_name += ".docx"
    return safe_name


def render_export_button(md_text: str, key=None):
    file_name = "PRD.docx"
    if "uploaded_filename" in st.session_state and st.session_state["uploaded_filename"]:
        file_name = st.session_state["uploaded_filename"]
    if st.download_button(
        label="å¯¼å‡º",
        data=markdown_to_docx_bytes(md_text),
        file_name=file_name,
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        key=key
    ):
        st.toast("å¯¼å‡ºæˆåŠŸï¼")


# ç¤ºä¾‹å‡½æ•°ï¼ˆè¯·æ ¹æ®å®é™…å®ç°æ›¿æ¢ï¼‰
def generateprd(prompt, file_text):
    test_cases = ["ä¸»é¡µå’Œdongleåˆ‡æ¢","å…³æœº","éŸ³é‡+","éŸ³é‡-","ä¸Šé”®","ä¸‹é”®","å·¦é”®","å³é”®","OKé”®","è‡ªåŠ¨å¯¹ç„¦é”®","muteé”®","è¿”å›é”®","ä¸»é¡µé”®","æ¯å±","æ‰“å¼€wifi","å…³é—­wifi","æ‰“å¼€BT","å…³é—­BT","è·å–å½“å‰è‡ªåŠ¨å¯¹ç„¦çŠ¶æ€","è·å–å½“å‰è‡ªåŠ¨æ¢¯å½¢çŠ¶æ€","è·å–å½“å‰æŠ•å½±ç¼©æ”¾æ¯”ä¾‹","è·å–å½“å‰å››ç‚¹æ¢¯å½¢åæ ‡"]
    if file_text:
        if not st.session_state.get("file_processed", False):
            full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ•å½±ä»ªäº§å“éœ€æ±‚æ–‡æ¡£ï¼ˆPRDï¼‰åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™ï¼Œé€é¡¹é€å­é¡¹å¯¹ç”¨æˆ·ä¸Šä¼ çš„ PRD æ–‡æ¡£è¿›è¡Œç»“æ„å®Œæ•´æ€§æ£€æµ‹ã€ç¼ºå¤±å†…å®¹æé—®ä¸æ™ºèƒ½è¡¥å…¨ï¼Œç¡®ä¿å†…å®¹å®Œæ•´ä¸”ä¸“ä¸šã€‚

---

ğŸš¦ æ‰§è¡Œæµç¨‹ï¼š

1. è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ PRD æ¨¡æ¿ç»“æ„ä¸­æ¯ä¸€é¡¹åŠå…¶å­é¡¹çš„é¡ºåºï¼Œé€é¡¹é€å­é¡¹æ£€æŸ¥ç”¨æˆ·ä¸Šä¼ çš„ PRD å†…å®¹ï¼›
2. æ¯æ¬¡ä»…å¤„ç†ä¸€ä¸ªå­é¡¹ï¼Œä¸å¾—ä¸€æ¬¡æ€§æé—®å¤šä¸ªç¼ºå¤±å†…å®¹ï¼Œè¿™ä¸ªå¾ˆé‡è¦ï¼›
3. å¯¹æ¯ä¸ªå­é¡¹å†…å®¹åˆ¤æ–­æ ‡å‡†å¦‚ä¸‹ï¼š

   * âœ… è‹¥è¯¥å­é¡¹å­˜åœ¨ä¸”åŒ…å«æœ‰æ•ˆå†…å®¹ï¼ˆéç©ºã€éå ä½ã€éä»…æ ‡é¢˜ï¼‰ï¼Œè¯·è·³è¿‡ï¼Œä¸æé—®ã€ä¸ä¿®æ”¹ã€ä¸æ‰©å†™ï¼›
   * âŒ è‹¥è¯¥å­é¡¹ç¼ºå¤±ï¼Œæˆ–å†…å®¹ä¸ºç©ºã€ä»…æœ‰æ ‡é¢˜ã€æˆ–ä¸ºå ä½è¯ï¼ˆå¦‚â€œæ— â€â€œå¾…è¡¥å……â€ç­‰ï¼‰ï¼Œè¯·æç¤ºç”¨æˆ·è¡¥å……ï¼›
   * æç¤ºç”¨æˆ·è¡¥å……çš„æ—¶å€™è¦å¸¦ä¸Šå­é¡¹çš„æ ‡é¢˜ï¼Œå­é¡¹ä¸ºæ¯ä¸€é¡¹çš„æœ€å°é¡¹æ ‡é¢˜ï¼›

4. å¯¹ç”¨æˆ·è¡¥å……çš„å†…å®¹ï¼Œæ‰§è¡Œï¼š

   * âœ¨ æ™ºèƒ½æ‰©å†™ï¼šè¡¥å…¨ä¸Šä¸‹æ–‡èƒŒæ™¯ã€ç»†èŠ‚ä¸æŠ€æœ¯é€»è¾‘ï¼Œå¤šå†™ç‚¹ï¼›
   * ğŸ’… ä¸“ä¸šæ¶¦è‰²ï¼šç¬¦åˆ PRD å†™ä½œè§„èŒƒï¼Œè¡¨è¾¾æ¸…æ™°ã€ç»“æ„ä¸¥è°¨ï¼›

5. å±•ç¤ºæ‰©å†™ç»“æœï¼Œå¹¶è¯¢é—®ç”¨æˆ·ï¼šâ€œæ˜¯å¦æ»¡æ„è¯¥å†…å®¹ï¼Ÿï¼ˆæ˜¯/å¦ï¼‰â€

   * æ˜¯ â†’ **æ— éœ€å›å¤ä¿å­˜æç¤ºï¼Œç«‹å³æ£€æµ‹ä¸‹ä¸€ä¸ªç¼ºå¤±çš„å­é¡¹ï¼Œç»§ç»­æé—®ï¼›**
   * å¦ â†’ æ ¹æ®ç”¨æˆ·åé¦ˆé‡æ–°æ‰©å†™è¯¥å­é¡¹ï¼›

6. å…¨éƒ¨å­é¡¹å®Œæˆåï¼Œä¸”æ²¡æœ‰ç¼ºå¤±é¡¹ï¼Œåˆ™ç›´æ¥è¾“å‡ºå®Œæ•´çš„ PRD æ–‡æ¡£å†…å®¹ï¼Œä¸ç”¨å›å¤å…¶ä»–ã€‚

---

ğŸ“ PRD æ¨¡æ¿ç»“æ„ï¼ˆå¿…é¡»é€é¡¹é€å­é¡¹æ ¸æŸ¥ï¼‰ï¼š

```

â”œâ”€ ä¸€ã€å‰ç½®æ¡ä»¶
â”‚   â””â”€ äº§å“ç›®æ ‡
â”œâ”€ äºŒã€åŠŸèƒ½éœ€æ±‚
â”‚   â”œâ”€ åŠŸèƒ½æ¸…å•
â”‚   â”œâ”€ æ•°æ®æŒ‡æ ‡
â”‚   â”œâ”€ åº”ç”¨åœºæ™¯
â”‚   â”‚   â”œâ”€ ä½¿ç”¨åœºæ™¯ï¼ˆå«åœºæ™¯è§„åˆ™ï¼‰
â”‚   â”‚   â”œâ”€ è¾¹ç•Œåˆ¤æ–­
â”‚   â”‚   â””â”€ åŠŸèƒ½ä¸UIäº¤äº’
â”‚   â””â”€ ç»“æ„å›¾
â”œâ”€ ä¸‰ã€éåŠŸèƒ½è¯´æ˜
â”‚   â”œâ”€ æ€§èƒ½æŒ‡æ ‡
â”‚   â”‚   â”œâ”€ é€Ÿåº¦
â”‚   â”‚   â””â”€ å¯é æ€§
â”‚   â””â”€ å…¼å®¹æ€§
â”œâ”€ å››ã€æµ‹è¯•æ–¹æ³•
â””â”€ äº”ã€éªŒæ”¶æ ‡å‡†

```

---

âš ï¸ å†…å®¹æœ‰æ•ˆæ€§åˆ¤å®šæ ‡å‡†ï¼š

1. **ä»…æœ‰æ ‡é¢˜ï¼ˆä¾‹å¦‚â€œé€Ÿåº¦ï¼šâ€ï¼‰ä½†æ— æ­£æ–‡å†…å®¹ï¼Œè§†ä¸ºæ— æ•ˆå†…å®¹ï¼Œå¿…é¡»æç¤ºç”¨æˆ·è¡¥å……ï¼›**

2. **å†…å®¹ä»…åŒ…å«ä»¥ä¸‹å ä½è¯ï¼Œè§†ä¸ºæ— æ•ˆï¼š**

```

\['æ— ', 'å¾…è¡¥å……', 'æ— å†…å®¹', 'N/A', 'æš‚æ— ', 'ç©º', 'ç©ºç™½', '-', 'æ— æ ‡é¢˜']

```

3. **å†…å®¹é•¿åº¦å°äº1å­—ï¼Œä¸”ä¸æ„æˆå®Œæ•´å¥å­ï¼Œè§†ä¸ºæ— æ•ˆï¼›**

4. **æœ‰æ•ˆå†…å®¹å¿…é¡»åŒ…å«å®Œæ•´çš„æè¿°æ€§è¯­å¥ï¼Œèƒ½å¤Ÿæ˜ç¡®è¡¨è¾¾è¯¥å­é¡¹çš„å†…å®¹æˆ–ç›®æ ‡ï¼›**

5. **æµ‹è¯•æ–¹æ³•å­—æ®µé™¤äº†ä¸Šè¿°åˆ¤æ–­å¤–ï¼Œè¿˜å¿…é¡»åŒ…å«ä¸‹åˆ—å…³é”®è¯ä¸ºåŠŸèƒ½ç‚¹ç”Ÿæˆå¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ¯ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½æŒ‰TestCase001ã€æ ‡é¢˜ã€å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤ã€æœŸæœ›ç»“æœåˆ—å‡ºæ¥ï¼š**

```

\['ä¸»é¡µå’Œdongleåˆ‡æ¢', 'å…³æœº', 'éŸ³é‡+', 'éŸ³é‡-', 'ä¸Šé”®', 'ä¸‹é”®', 'å·¦é”®', 'å³é”®', 'OKé”®',
'è‡ªåŠ¨å¯¹ç„¦é”®', 'muteé”®', 'è¿”å›é”®', 'ä¸»é¡µé”®', 'æ¯å±', 'æ‰“å¼€wifi', 'å…³é—­wifi', 'æ‰“å¼€BT', 'å…³é—­BT', 
'è·å–å½“å‰è‡ªåŠ¨å¯¹ç„¦çŠ¶æ€', 'è·å–å½“å‰è‡ªåŠ¨æ¢¯å½¢çŠ¶æ€', 'è·å–å½“å‰æŠ•å½±ç¼©æ”¾æ¯”ä¾‹', 'è·å–å½“å‰å››ç‚¹æ¢¯å½¢åæ ‡']

```

ğŸ“Œ ä¿ç•™ç”¨æˆ·è‡ªå®šä¹‰å­é¡¹è§„åˆ™ï¼š

åœ¨å¤„ç†ç”¨æˆ·æä¾›çš„ PRD æ–‡æ¡£æ—¶ï¼Œå¯èƒ½å‡ºç°éæ¨¡æ¿å®šä¹‰çš„è‡ªå®šä¹‰å­—æ®µï¼Œè¯·ä¿ç•™ï¼Œä¾‹å¦‚ï¼š

- â€œèƒŒæ™¯ä»‹ç»ï¼ˆå¯é€‰ï¼‰â€
- â€œåè¯è§£é‡Šâ€
- â€œæµç¨‹å›¾â€

```

æœ€ç»ˆè¯·å°† PRD å†…å®¹æ•´ç†ä¸ºæ¸…æ™°çš„ **Word æ’ç‰ˆé£æ ¼æ ¼å¼**ï¼Œåˆ†çº§æ ‡é¢˜æ ·å¼å¦‚ä¸‹ï¼š

---

**ä¸€ã€å‰ç½®æ¡ä»¶**

* **äº§å“ç›®æ ‡ï¼š** xxx

---

**äºŒã€åŠŸèƒ½éœ€æ±‚**

* **åŠŸèƒ½æ¸…å•ï¼š** xxx
* **æ•°æ®æŒ‡æ ‡ï¼š** xxx

**åº”ç”¨åœºæ™¯ï¼š**

* **ä½¿ç”¨åœºæ™¯ï¼ˆå«åœºæ™¯è§„åˆ™ï¼‰ï¼š** xxx

* **è¾¹ç•Œåˆ¤æ–­ï¼š** xxx

* **åŠŸèƒ½ï¼š** xxx

* **UIäº¤äº’ï¼š** xxx

* **ç»“æ„å›¾ï¼š** xxx

---

**ä¸‰ã€éåŠŸèƒ½è¯´æ˜**

* **æ€§èƒ½æŒ‡æ ‡ï¼š**

  * **é€Ÿåº¦ï¼š** xxx
  * **å¯é æ€§ï¼š** xxx
* **å…¼å®¹æ€§ï¼š** xxx

---

**å››ã€æµ‹è¯•æ–¹æ³•ï¼š**

* xxxï¼ˆåŒ…å«è‡³å°‘ä¸€ä¸ªå…³é”®è¯ï¼‰

---

**äº”ã€éªŒæ”¶æ ‡å‡†ï¼š**

* xxx

---

ğŸ§ª ç¤ºä¾‹ï¼ˆä»…ä¾›ç†è§£ï¼Œä¸ä¸ºæç¤ºè¯æ­£æ–‡ï¼‰ï¼š

- â€œé€Ÿåº¦ï¼šâ€ â†’ æ— æ•ˆï¼ˆä»…æ ‡é¢˜æ— å†…å®¹ï¼‰éœ€è¡¥å……ï¼›

- â€œé€Ÿåº¦ï¼š3ç§’å†…å¼€æœºâ€ â†’ æœ‰æ•ˆï¼Œè·³è¿‡ï¼›

- â€œæµ‹è¯•æ–¹æ³•ï¼šæ— â€ â†’ æ— æ•ˆï¼Œéœ€è¡¥å……ï¼›

- â€œæµ‹è¯•æ–¹æ³•ï¼šåŒ…å«â€˜å…³æœºâ€™æ­¥éª¤â€ â†’ æœ‰æ•ˆï¼Œè·³è¿‡ã€‚

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè§„åˆ™æ‰§è¡Œï¼Œé€é¡¹é€å­é¡¹å®Œæˆ PRD æ£€æŸ¥ä¸è¡¥å……ï¼Œç¡®ä¿å†…å®¹å®Œæ•´ä¸”ç¬¦åˆä¸“ä¸šè§„èŒƒã€‚
```

ç”¨æˆ·ä¸Šä¼ çš„ PRD æ–‡æœ¬å¦‚ä¸‹ï¼š{file_text}"""
            # msg = send_prompt_with_timeout(full_prompt)
            response = st.session_state.chat.send_message(
            full_prompt, stream=False, generation_config=gen_config)
            st.session_state["file_processed"] = True
        else:
            # msg = send_prompt_with_timeout(prompt)
            response = st.session_state.chat.send_message(
            prompt, stream=False, generation_config=gen_config)
    else:
        if not st.session_state.get("text_processed", False):
            full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„**æŠ•å½±ä»ªäº§å“éœ€æ±‚æ–‡æ¡£ï¼ˆPRDï¼‰åŠ©æ‰‹**ï¼Œè¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ã€äº§å“åç§°ã€‘ï¼Œé€é¡¹å¼•å¯¼ç”¨æˆ·å¡«å†™ PRD å†…å®¹ï¼Œå…·ä½“è¦æ±‚å¦‚ä¸‹ï¼š

---

### ğŸ“‹ æ‰§è¡Œè§„åˆ™ï¼š

1. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ PRD æ¨¡æ¿ç»“æ„é€é¡¹å¼•å¯¼ç”¨æˆ·è¾“å…¥ï¼›
2. ç”¨æˆ·è¾“å…¥åï¼Œä½ éœ€å¯¹è¯¥é¡¹å†…å®¹è¿›è¡Œ**æ‰©å†™å’Œæ¶¦è‰²**ï¼Œä½¿å…¶ç¬¦åˆä¸“ä¸š PRD å†™ä½œè§„èŒƒï¼›
3. æ‰©å†™åï¼Œå±•ç¤ºè¯¥é¡¹å†…å®¹å¹¶è¯¢é—®ç”¨æˆ·æ˜¯å¦æ»¡æ„ï¼š

   * è‹¥æ»¡æ„ï¼Œç»§ç»­ä¸‹ä¸€é¡¹ï¼›
   * è‹¥ä¸æ»¡æ„ï¼Œæ ¹æ®ç”¨æˆ·åé¦ˆé‡æ–°æ‰©å†™ï¼Œç›´åˆ°æ»¡æ„ï¼›
4. æ‰€æœ‰é¡¹å¡«å†™å®Œæ¯•åï¼Œç”Ÿæˆå¹¶è¾“å‡ºå®Œæ•´çš„ PRD æ–‡æ¡£ï¼Œæ’ç‰ˆéœ€éµå¾ª Word é£æ ¼ç»“æ„ã€‚

---

### ğŸ“‚ PRD æ¨¡æ¿ç»“æ„å¦‚ä¸‹ï¼š

```
ä¸€ã€å‰ç½®æ¡ä»¶
â””â”€ äº§å“ç›®æ ‡

äºŒã€åŠŸèƒ½éœ€æ±‚
â”œâ”€ åŠŸèƒ½æ¸…å•
â”œâ”€ æ•°æ®æŒ‡æ ‡
â”œâ”€ åº”ç”¨åœºæ™¯
â”‚   â”œâ”€ ä½¿ç”¨åœºæ™¯ï¼ˆå«åœºæ™¯è§„åˆ™ï¼‰
â”‚   â”œâ”€ è¾¹ç•Œåˆ¤æ–­
â”‚   â””â”€ åŠŸèƒ½ä¸UIäº¤äº’
â””â”€ ç»“æ„å›¾

ä¸‰ã€éåŠŸèƒ½è¯´æ˜
â”œâ”€ æ€§èƒ½æŒ‡æ ‡
â”‚   â”œâ”€ é€Ÿåº¦
â”‚   â””â”€ å¯é æ€§
â””â”€ å…¼å®¹æ€§

å››ã€æµ‹è¯•æ–¹æ³•

äº”ã€éªŒæ”¶æ ‡å‡†
```

### âš ï¸ ç‰¹åˆ«è¯´æ˜ï¼šæµ‹è¯•æ–¹æ³•å­—æ®µ

åœ¨æ ¡éªŒ **â€œæµ‹è¯•æ–¹æ³•â€** å­—æ®µæ—¶ï¼Œè¯·ç¡®ä¿å…¶å†…å®¹ä¸­åŒ…å«ä»¥ä¸‹å…³é”®è¯åˆ—è¡¨ä¸­çš„**è‡³å°‘ä¸€ä¸ª**ï¼Œå¦åˆ™è§†ä¸ºç¼ºå¤±ï¼š

{test_cases}

### ğŸ§­ å·¥ä½œæµç¨‹ï¼š

* å½“å‰äº§å“åç§°ï¼š**ï¼ˆç”±ç”¨æˆ·å¡«å†™ï¼‰**
* å½“å‰æ¨¡å—ï¼šé€é¡¹æé—® â†’ ç”¨æˆ·è¡¥å…… â†’ è‡ªåŠ¨æ‰©å†™ â†’ ç”¨æˆ·ç¡®è®¤ â†’ ç»§ç»­ä¸‹ä¸€é¡¹
* æ‰€æœ‰æ¨¡å—å¡«å†™å®Œæ¯•åï¼Œè¾“å‡ºå®Œæ•´ Word é£æ ¼çš„ PRD æ–‡æ¡£

---

### ğŸ“„ è¾“å‡ºæ’ç‰ˆé£æ ¼è¦æ±‚ï¼ˆæ¨¡æ‹Ÿ Word æ ·å¼ï¼‰ï¼š

---

**äº§å“åç§°ï¼šXXX**

---

**ä¸€ã€å‰ç½®æ¡ä»¶**

* **äº§å“ç›®æ ‡ï¼š** xxxï¼ˆè‡ªåŠ¨æ‰©å†™åçš„å†…å®¹ï¼‰

---

**äºŒã€åŠŸèƒ½éœ€æ±‚**

* **åŠŸèƒ½æ¸…å•ï¼š** xxx
* **æ•°æ®æŒ‡æ ‡ï¼š** xxx

**åº”ç”¨åœºæ™¯ï¼š**

* **ä½¿ç”¨åœºæ™¯ï¼ˆå«åœºæ™¯è§„åˆ™ï¼‰ï¼š** xxx

* **è¾¹ç•Œåˆ¤æ–­ï¼š** xxx

* **åŠŸèƒ½ï¼š** xxx

* **UIäº¤äº’ï¼š** xxx

* **ç»“æ„å›¾ï¼š** xxx

---

**ä¸‰ã€éåŠŸèƒ½è¯´æ˜**

* **æ€§èƒ½æŒ‡æ ‡ï¼š**

  * **é€Ÿåº¦ï¼š** xxx
  * **å¯é æ€§ï¼š** xxx
* **å…¼å®¹æ€§ï¼š** xxx

---

**å››ã€æµ‹è¯•æ–¹æ³•ï¼š**

* xxxï¼ˆç¡®ä¿å«æœ‰è‡³å°‘ä¸€ä¸ªå…³é”®æµ‹è¯•å…³é”®è¯ï¼‰

---

**äº”ã€éªŒæ”¶æ ‡å‡†ï¼š**

* xxx

---

è¯·æ ¹æ®ä¸Šæ–¹é€»è¾‘ï¼Œä¸ç”¨æˆ·å¼€å§‹äº¤äº’ï¼Œè¿™ä¸ªæ˜¯äº§å“åç§°ï¼š{prompt}"""
            # msg = send_prompt_with_timeout(full_prompt)
            response = st.session_state.chat.send_message(
            full_prompt, stream=False, generation_config=gen_config)
            st.session_state["text_processed"] = True
        else:
            # msg = send_prompt_with_timeout(prompt)
            response = st.session_state.chat.send_message(
            prompt, stream=False, generation_config=gen_config)

    msg = response.text
    return msg


def generate_test_case_json(user_input):
    test_case_model_path = './test_case_model.json'
    test_case_model = ""

    try:
        with open(test_case_model_path, 'r', encoding='utf-8') as file:
            test_case_model = file.read()
    except FileNotFoundError:
        print(f"Error: The file '{test_case_model_path}' was not found.")
        st.toast(f"Error: The file '{test_case_model_path}' was not found.")
    except Exception as e:
        print(f"An error occurred: {e}")
        st.toast(f"An error occurred: {e}")

    if test_case_model:
        if not st.session_state.get("test_case_processed", False):
            prompt = f"""è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ‰§è¡Œä»»åŠ¡ï¼š

    ---

    ### ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼š

    ä½ éœ€è¦**ä»…ä»ä¸‹é¢æˆ‘æä¾›çš„å®Œæ•´ JSON æ¨¡æ¿ä¸­**ï¼Œæ ¹æ®ä¸Šæ–¹ PRD æµ‹è¯•æ–¹æ³•ç›¸å…³çš„æ¨¡å—ï¼ˆé€šè¿‡ `moduleKey` åŒ¹é…ï¼‰ï¼Œå¦‚æœä¸Šé¢æ²¡æœ‰PRDæµ‹è¯•æ–¹æ³•ï¼Œåˆ™æŒ‰ä¸‹é¢JSONæ¨¡ç‰ˆå®Œæ•´è¾“å‡ºï¼Œ**åŸæ ·è¾“å‡ºæ‰€é€‰æ¨¡å—çš„ JSON å†…å®¹**ï¼Œç”¨äºåç»­æµ‹è¯•ä»£ç ç”Ÿæˆã€‚

    ---

    ### âš ï¸ ä¸¥æ ¼é™åˆ¶ï¼š

    * **ä¸èƒ½ä¿®æ”¹** JSON æ¨¡æ¿ä¸­çš„å­—æ®µåã€å­—æ®µå€¼ã€å­—æ®µé¡ºåºã€åµŒå¥—ç»“æ„ï¼›
    * **ä¸èƒ½æ–°å¢ã€åˆ é™¤æˆ–è¡¥å…¨**æ¨¡å—ã€å­—æ®µæˆ–æ¡ˆä¾‹ï¼›
    * **åªèƒ½ä»æ¨¡æ¿ä¸­é€‰å–æ¨¡å—ï¼Œå¹¶è¾“å‡ºåŸå§‹ JSON å†…å®¹ï¼Œå…¶ä»–å…¨éƒ¨å¿½ç•¥**ï¼›
    * **è¾“å‡ºçš„JSONå¿…é¡»ä¸ºåŒå¼•å·çš„JSONï¼›
    * **è¾“å‡ºç»“æœåªèƒ½ä¸º JSON å†…å®¹æœ¬èº«ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•è§£é‡Šè¯´æ˜ã€é¢å¤–æ–‡å­—ã€æ ‡ç‚¹ã€å‰åç¼€ã€æ³¨é‡Šç­‰**ã€‚

    ---

    ### âœ… è¾“å‡ºç¤ºä¾‹ï¼š

    ä»…å½“é€‰ä¸­æ¨¡å—ä¸º `systemControl` ä¸ `wifiTest` æ—¶ï¼Œåº”è¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š

    ```json
    {[
    {
        "moduleKey": "systemControl",
        "moduleName": "ç³»ç»Ÿæ§åˆ¶",
        "features": [
        ...
        ]
    },
    {
        "moduleKey": "wifiTest",
        "moduleName": "WiFiæµ‹è¯•",
        "features": [
        ...
        ]
    }
    ]}
    ```

    ---

    ### ğŸ“Œ æ¨¡æ¿å¦‚ä¸‹ï¼ˆåªå…è®¸ä»æ­¤æ¨¡æ¿ä¸­é€‰å–æ¨¡å—ï¼Œæ— ä»»ä½•æ”¹åŠ¨ï¼‰ï¼š

    {test_case_model}

    ---

    {user_input}

    """
            response = st.session_state.chat.send_message(
                    prompt, stream=False, generation_config=gen_config)
        else:
            # prompt = f"æ ¹æ®{user_input}ï¼Œå®‰ç…§è¿™ä¸ªæ¨¡ç‰ˆ{test_case_model}é€‰å‡ºå¯¹åº”çš„JSONæµ‹è¯•ä»£ç "
            response = st.session_state.chat.send_message(
                user_input, stream=False, generation_config=gen_config)
        response.resolve()
        msg = response.text
        match = re.search(r'\[\s*{.*}\s*\]', msg, re.DOTALL)
        if match:
            json_str = match.group(0)  # æå–åŒ¹é…åˆ°çš„ JSON å­—ç¬¦ä¸²
            try:
                # ä¼˜å…ˆå°è¯•æ ‡å‡† JSON
                data = json.loads(json_str)
            except json.JSONDecodeError as e:
                print(f"è§£æ JSON å¤±è´¥: {e}")
                try:
                    # å›é€€ä½¿ç”¨ ast.literal_eval å¤„ç†ç±» Python æ ¼å¼ï¼ˆå•å¼•å·ï¼‰
                    data = ast.literal_eval(json_str)
                except Exception as e:
                    print(f"è§£æå¤±è´¥: {e}")
                    return msg
            st.session_state["test_case_processed"] = True
            st.session_state["test_case_json"] = data
            return data
    else:
        msg = "è¯·å°†æµ‹è¯•ç”¨ä¾‹æ¨¡ç‰ˆæ–‡ä»¶ï¼štest_case_model.jsonæ”¾åˆ°å½“å‰ç›®å½•"
    return msg


def generatetestscripts(input_text):
    """
    ä½¿ç”¨ Gemini æ¨¡å‹æ ¹æ®è‡ªç„¶è¯­è¨€è¾“å…¥ç”Ÿæˆ Linux Shell è„šæœ¬ã€‚
    """

    file_path = './test_function.sh'
    shell_save_dir = './temp'
    test_case_str = ""

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
    except FileNotFoundError:
        print(f"Error: The file '{file_path}' was not found.")
        return f"Error: The file '{file_path}' was not found."
    except Exception as e:
        print(f"An error occurred: {e}")
        return f"An error occurred: {e}"

    if st.session_state.get("test_case_processed"):
        st.session_state["test_case_processed"] = False
        data = st.session_state["test_case_json"]
        step_list = jsonpath.jsonpath(data, '$..steps') or []
        if step_list:
            for step in step_list:
                test_case_str = ';'.join(map(str, step))

    print(test_case_str)

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªç†Ÿç»ƒçš„ Linux Shell è„šæœ¬å·¥ç¨‹å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ Bash è„šæœ¬ï¼š

æ‰§è¡Œè§„åˆ™ï¼š
    1ã€ä¼˜å…ˆä»å‡½æ•°åº“ä¸­é€‰æ‹©æµ‹è¯•å‡½æ•°ï¼šå¦‚æœå‡½æ•°åº“ä¸­å­˜åœ¨å¯ç›´æ¥ç”¨äºæµ‹è¯•çš„å‡½æ•°ï¼Œä¼˜å…ˆè°ƒç”¨è¿™äº›å‡½æ•°ï¼Œä¸è¦ä¿®æ”¹å‡½æ•°çš„ä»»ä½•é€»è¾‘ï¼Œç›´æ¥è°ƒç”¨å³å¯ã€‚
    2ã€è‹¥åº“ä¸­æ— åˆé€‚å‡½æ•°ï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼šç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹åº”ç‹¬ç«‹ã€å¯æ‰§è¡Œã€‚
    3ã€ç¦æ­¢ä½¿ç”¨ adb shell å…³é”®å­—ï¼Œæ²¡æœ‰ç”¨åˆ°çš„å‡½æ•°ä¸ç”¨æ˜¾ç¤ºå‡ºæ¥ï¼Œç®€æ´æ˜“æ‡‚ã€‚
    4ã€è¾“å‡ºæ ¼å¼ï¼ˆæ ¹æ®éœ€æ±‚é€‰æ‹©ï¼‰ï¼šè„šæœ¬ä»¥ #!/bin/sh å¼€å¤´ã€‚
    5ã€å‡½æ•°åº“å¦‚ä¸‹ï¼š
{content}

éœ€æ±‚æè¿°ï¼š
{test_case_str}\n
{input_text}

è¯·è¾“å‡ºæ­£ç¡®è°ƒç”¨å‡½æ•°çš„è„šæœ¬å†…å®¹ã€‚
"""
    prompt2 = f"""
ä½ æ˜¯ä¸€ä¸ªç†Ÿç»ƒçš„ Linux Shell è„šæœ¬å·¥ç¨‹å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ Bash è„šæœ¬ï¼š

éœ€æ±‚æè¿°ï¼š
{input_text}

è¯·è¾“å‡ºä¿®æ”¹åçš„è„šæœ¬å†…å®¹ï¼Œä»…æä¾›ä»£ç å°±å¯ä»¥äº†ã€‚
"""

    if not st.session_state.get("shell_processed", False):
        response = st.session_state.chat.send_message(prompt, stream=True)
        st.session_state["shell_processed"] = True
    else:
        response = st.session_state.chat.send_message(prompt2, stream=True)

    response.resolve()
    os.makedirs(shell_save_dir, exist_ok=True)
    shell_save_path = os.path.join(shell_save_dir, "ai_tmp.sh")
    shell_file_content = response.text.removeprefix("```bash").strip()
    backtick_pos = shell_file_content.find('```')
    if backtick_pos != -1:
        last_file_content = shell_file_content[:backtick_pos]
        with open(shell_save_path, "w", newline='\n', encoding="utf-8") as f:
            f.write(last_file_content)

    return response.text


def sleep_time(user_time):
    progress_bar = st.progress(0)
    status_text = st.empty()

    for i in range(user_time):
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress((i + 1.0) / user_time)
        status_text.text(f"logæŠ“å–ä¸­è¿˜å‰©ï¼š{i + 1}/{user_time} ç§’")
        time.sleep(1)

    status_text.text("logæŠ“å–å®Œæˆï¼")
    progress_bar.empty()


def run_scripts():
    tmp_shell_path = Path('./temp/ai_tmp.sh').resolve()
    result = subprocess.run(["adb", "push", tmp_shell_path, "sdcard"], shell=True)
    print("push ai_tmp.sh success:", result.returncode)  # 0 è¡¨ç¤ºæˆåŠŸ
    if result.returncode == 0:
        subprocess.run(["adb", "root"], shell=True)
        process = subprocess.Popen("adb shell sh sdcard/ai_tmp.sh", shell=True, stdout=subprocess.PIPE,
                                encoding='utf-8', errors='ignore')
        # å®æ—¶è¯»å–è¾“å‡ºï¼ˆé€‚ç”¨äºé•¿æ—¶é—´è¿è¡Œçš„å‘½ä»¤ï¼‰
        while True:
            output = process.stdout.readline()
            if output == "" and process.poll() is not None:
                break
            if output:
                st.chat_message("assistant").write(output.strip())

        # è·å–æœ€ç»ˆè¿”å›ç 
        return_code = process.wait()
        if return_code == 0:
            exe_msg = "è„šæœ¬æ‰§è¡ŒæˆåŠŸï¼Œæ­£åœ¨è·å–å½“å‰æ˜¾ç¤ºå†…å®¹ï¼Œè¯·ç¨ç­‰ã€‚ã€‚ã€‚"
            st.chat_message("assistant").write(exe_msg)
        else:
            exe_msg = "è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·å°è¯•ä¿®æ”¹è„šæœ¬æˆ–è€…é‡æ–°ç”Ÿæˆ"
            st.chat_message("assistant").write(exe_msg)

        result = subprocess.run("adb shell screencap -p sdcard/cap.png", shell=True)
        print("get screen cap success:", result.returncode)
        save_dir = "screen"
        os.makedirs(save_dir, exist_ok=True)
        tmp_cap_path = Path('./screen/').resolve()
        result = subprocess.run(["adb", "pull", "sdcard/cap.png", tmp_cap_path], shell=True)
        if result.returncode == 0:
            image = Image.open("./screen/cap.png")
            st.image(image, caption='è®¾å¤‡å½“å‰æ˜¾ç¤ºå†…å®¹', use_container_width=True)
    else:
        exe_msg = "è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¡®è®¤æ˜¯å¦ADBè¿æ¥ä¸Šäº†è®¾å¤‡"
        st.chat_message("assistant").write(exe_msg)


def debug_logcat_file(input_text):
    log_path = './log/system_log.txt'
    logcat_sh_path = os.path.join(os.path.dirname(__file__), "logcat.sh")

    if os.path.exists(log_path):
        os.remove(log_path)

    match = re.search(r'(\d+)s', input_text)
    if match:
        use_time = int(match.group(1))
    else:
        match = re.search(r'(\d+)min', input_text)
        if match:
            use_time = int(match.group(1))
            use_time = 60 * use_time
        else:
            use_time = 0

    match = re.search(r'TAG=([a-zA-Z]+)', input_text)
    if match:
        tag = match.group(1)
    else:
        tag = "null"

    with open(logcat_sh_path, 'r', encoding='utf-8') as f:
        content = f.read()
        if use_time != 0:
            modified_content = re.sub(r'sleep \d+', "sleep " + str(use_time), content)
        else:
            use_time = 5
            first_content = re.sub(r'logcat -c', "", content)
            modified_content = re.sub(r'sleep \d+', "sleep " + str(use_time), first_content)

        if tag != "null":
            last_content = re.sub(r'LOG_TAG="([a-zA-Z]+)"', "LOG_TAG=" + '"' + tag + '"', modified_content)
        else:
            last_content = re.sub(r'LOG_TAG="([a-zA-Z]+)"', 'LOG_TAG="AndroidRuntime | DEBUG"', modified_content)

    with open(logcat_sh_path, 'w', newline='\n', encoding='utf-8') as f:
        if tag != "null":
            f.write(last_content)
        else:
            f.write(modified_content)

    result = subprocess.run(["adb", "push", logcat_sh_path, "sdcard"], shell=True)
    if result.returncode == 0:
        result = subprocess.run('adb shell "nohup sh sdcard/logcat.sh > /dev/null 2>&1 &"', shell=True)
        if result.returncode == 0:
            sleep_time(use_time)
            save_dir = "log"
            os.makedirs(save_dir, exist_ok=True)
            tmp_log_path = Path('./log/').resolve()
            result = subprocess.run(["adb", "pull", r"sdcard/system_log.txt", tmp_log_path], shell=True)
            if result.returncode == 0:
                print("system_log.txt pull success")
            else:
                print("system_log.txt pull failed")
        else:
            print("logcat.sh run failed")
    else:
        return "è®¾å¤‡æ²¡æœ‰è¿æ¥ä¸ŠADBï¼Œè¯·è¿æ¥åé‡è¯•"

    try:
        with open(log_path, 'r', encoding='utf-8') as file:
            logcat_content = file.read()
    except FileNotFoundError:
        print(f"Error: The file '{log_path}' was not found.")
    except Exception as e:
        print(f"An error occurred: {e}")

    if logcat_content.__len__() < 100:
        return "æ²¡æœ‰æŠ“åˆ°é”™è¯¯æ—¥å¿—ä¿¡æ¯"

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªç†Ÿç»ƒçš„Androidç³»ç»Ÿå·¥ç¨‹å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹è‡ªç„¶è¯­è¨€æè¿°åˆ†ææ—¥å¿—ï¼š

    éœ€æ±‚æè¿°ï¼š
    {logcat_content}è¿™æ˜¯æŠ“å–çš„ç³»ç»Ÿlog\n
    {input_text}
    
    """

    response = st.session_state.chat.send_message(prompt, stream=True)
    response.resolve()
    return response.text



# PRD æ¨¡å¼ç³»ç»Ÿæç¤º
roleprompt = """
ä½ å¥½ï¼Œæˆ‘å¯ä»¥å¸®ä½ ï¼Œç”ŸæˆPRDæµ‹è¯•æ–‡æ¡£ï¼Œç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå†™æµ‹è¯•shellè„šæœ¬ï¼ŒDebugæ—¥å¿—åˆ†æ:\n
è¯·åœ¨å·¦ä¾§æ ä¸­é€‰æ‹©å¯¹åº”çš„è¾“å…¥æ¨¡å¼ï¼š\n
PRDæ¨¡å¼ï¼šç”ŸæˆPRDæµ‹è¯•æ–‡æ¡£ \n
TestCaseæ¨¡å¼ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ \n
Shellæ¨¡å¼ï¼šå†™æµ‹è¯•shellè„šæœ¬ \n
Debugï¼šæ—¥å¿—åˆ†æ \n

"""

st.set_page_config(page_title="Gemini Pro with Streamlit", page_icon="â™Š")
st.title("é›¶ç¼ºé™·Agent")

st.write("æ¬¢è¿æ¥åˆ° Gemini Pro èŠå¤©æœºå™¨äººã€‚æ‚¨å¯ä»¥é€šè¿‡æä¾›æ‚¨çš„ Google API å¯†é’¥æ¥ç»§ç»­ã€‚")

with st.expander("æä¾›æ‚¨çš„ Google API å¯†é’¥"):
    google_api_key = st.text_input("Google API å¯†é’¥", key="google_api_key", type="password")

if not google_api_key:
    st.info("è¯·è¾“å…¥ Google API å¯†é’¥ä»¥ç»§ç»­")
    st.stop()

genai.configure(api_key=google_api_key)


def reset_select_options():
    st.session_state.select_option = "Auto"


with st.sidebar:
    option = st.selectbox('é€‰æ‹©æ‚¨çš„æ¨¡å‹', ('gemini-2.0-flash', 'gemini-2.0-flash-lite'))

    if 'model' not in st.session_state or st.session_state.model != option:
        st.session_state.chat = genai.GenerativeModel(option).start_chat(history=[])
        st.session_state.model = option

    st.write("åœ¨æ­¤å¤„è°ƒæ•´æ‚¨çš„å‚æ•°:")
    temperature = st.number_input("æ¸©åº¦", min_value=0.0, max_value=1.0, value=0.5, step=0.01)
    max_token = st.number_input("æœ€å¤§è¾“å‡ºä»¤ç‰Œæ•°", min_value=0, value=10000)
    gen_config = genai.types.GenerationConfig(max_output_tokens=max_token, temperature=temperature)
    if 'select_option' not in st.session_state:
        st.session_state.select_option = "Auto"
    input_mode = st.selectbox(
        label='è¯·é€‰æ‹©è¾“å…¥æ¨¡å¼ï¼š',
        options=('Auto', 'Prd', 'TestCase', 'Shell', 'Debug'),
        index=0,
        format_func=str,
        key='select_option'
    )
    st.divider()

    upload_file = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£ï¼ˆæ”¯æŒ .docx, .pdf, .xls, .xlsxï¼‰",
        accept_multiple_files=False,
        type=["docx", "pdf", "xls", "xlsx"]
    )

    file_text = ""
    if upload_file:
        file_details = {
            "filename": upload_file.name,
            "filetype": upload_file.type,
            "filesize": upload_file.size
        }
        st.write("æ–‡ä»¶ä¿¡æ¯ï¼š", file_details)

        if upload_file.type == "application/pdf":
            reader = PyPDF2.PdfReader(upload_file)
            file_text = "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])
        elif upload_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            doc = docx.Document(upload_file)
            file_text = "\n".join([para.text for para in doc.paragraphs])
        elif upload_file.type in ["application/vnd.ms-excel",
                                  "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"]:
            df = pd.read_excel(upload_file)
            file_text = df.to_csv(index=False)

        if st.session_state.get("uploaded_filename") != upload_file.name:
            st.session_state["file_processed"] = False
            st.session_state["uploaded_filename"] = upload_file.name

            if input_mode == "Prd":
                st.session_state.chat_mode = input_mode
                msg = generateprd("", file_text)
                st.session_state.messages.append({"role": "assistant", "content": msg})
                st.chat_message("assistant").write(msg)

    st.divider()

    if st.button("æ¸…é™¤èŠå¤©å†å²", on_click=reset_select_options):
        st.session_state.messages = [{"role": "system", "content": roleprompt}]
        st.session_state.chat_mode = "Auto"
        st.session_state["uploaded_filename"] = ""

# åˆå§‹åŒ–èŠå¤©çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "system", "content": roleprompt}]
if "chat_mode" not in st.session_state:
    st.session_state["chat_mode"] = "Auto"

# æ˜¾ç¤ºå†å²è®°å½•
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # åˆ‡æ¢æ¨¡å¼
    # prompt_lower = prompt.lower()
    # if prompt_lower.startswith("prd@"):
    #     st.session_state["chat_mode"] = "Prd"
    #     st.session_state["file_processed"] = False
    #     st.session_state["text_processed"] = False
    #     user_input = prompt.removeprefix("Prd@").strip()
    # elif prompt_lower.startswith("testcase@"):
    #     st.session_state["chat_mode"] = "TestCase"
    #     st.session_state["test_case_processed"] = False
    #     user_input = prompt.removeprefix("TestCase@").strip()
    # elif prompt_lower.startswith("test@"):
    #     st.session_state["chat_mode"] = "Test"
    #     count_script = 0
    #     user_input = prompt.removeprefix("Test@").strip()
    # elif prompt_lower.startswith("debug@"):
    #     st.session_state["chat_mode"] = "Debug"
    #     user_input = prompt.removeprefix("Debug@").strip()
    # else:
    #     user_input = prompt
    #     count_script = 1

    if input_mode != st.session_state.chat_mode:
        st.session_state.chat_mode = input_mode
        if input_mode == "Prd":
            st.session_state["file_processed"] = False
            st.session_state["text_processed"] = False
        elif input_mode == "TestCase":
            st.session_state["test_case_processed"] = False
        elif input_mode == "Shell":
            st.session_state["shell_processed"] = False
        elif input_mode == "Debug":
            st.session_state["debug_processed"] = False

    # æ ¹æ®æ¨¡å¼å¤„ç†è¾“å…¥
    if st.session_state["chat_mode"] == "Prd":
        msg = generateprd(prompt, file_text)

    elif st.session_state["chat_mode"] == "TestCase":
        msg = generate_test_case_json(prompt)

    elif st.session_state["chat_mode"] == "Shell":
        msg = generatetestscripts(prompt)

    elif st.session_state["chat_mode"] == "Debug":
        msg = debug_logcat_file(prompt)
    else:
        response = st.session_state.chat.send_message(prompt, stream=True)
        response.resolve()
        msg = response.text

    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)

# ä¿å­˜ PRD æŒ‰é’®
# if st.session_state["chat_mode"] == "Prd":
#     if st.button("ä¿å­˜ä¿®æ”¹çš„PRDåˆ°æœ¬åœ°æ–‡ä»¶"):
#         last_assistant_msg = None
#         for message in reversed(st.session_state.messages):
#             if message["role"] == "assistant":
#                 last_assistant_msg = message["content"]
#                 break

#         if last_assistant_msg:
#             save_dir = "D:/LLM_Gemini_Pro_Streamlit/"
#             os.makedirs(save_dir, exist_ok=True)
#             save_path = os.path.join(save_dir, "ä¿®æ”¹åçš„PRD.txt")

#             with open(save_path, "w", encoding="utf-8") as f:
#                 f.write(last_assistant_msg)

#             st.success(f"PRD å·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: {save_path}")
#         else:
#             st.warning("æ²¡æœ‰æ‰¾åˆ°å¯ä»¥ä¿å­˜çš„å›å¤å†…å®¹ã€‚")

if st.session_state["chat_mode"] == "Shell":
    if st.button("æ‰§è¡Œè„šæœ¬"):
        run_scripts()
elif st.session_state["chat_mode"] == "Prd":
    messages = st.session_state.messages
    if len(messages) > 0 and messages[len(messages) - 1]["role"] == "assistant":
        render_export_button(messages[len(messages) - 1]["content"], "export_doc")