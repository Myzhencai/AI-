import streamlit as st
from PIL import Image
import google.generativeai as genai
import io
import docx
import PyPDF2
import markdown2
from docx import Document
from bs4 import BeautifulSoup
import pypandoc
import tempfile
from io import BytesIO
import base64
import streamlit.components.v1 as components
import re
import pyperclip
import os
from dotenv import load_dotenv
load_dotenv()


if "HTTP_PROXY" in os.environ and "HTTPS_PROXY" in os.environ:
    # ä¸¤ä¸ªéƒ½å­˜åœ¨ï¼Œæ‰§è¡Œè®¾ç½®ä»£ç†
    os.environ['http_proxy'] = os.getenv("HTTP_PROXY")
    os.environ['https_proxy'] = os.getenv("HTTPS_PROXY")
    print("ä»£ç†è®¾ç½®å®Œæˆ")
else:
    print("HTTP_PROXY æˆ– HTTPS_PROXY æœªé…ç½®ï¼Œè·³è¿‡ä»£ç†è®¾ç½®")

# pypandoc.pandoc_path = r'C:\Users\Puture\AppData\Local\Pandoc\pandoc.exe'

st.set_page_config(page_title="Gemini Pro with Streamlit", page_icon="â™Š")

st.markdown("""
    <style>
    /* é¼ æ ‡æ‚¬åœæ—¶çº¢è‰²è¾¹æ¡†ï¼Œä¸ç®¡æ˜¯å¦focus */
    button:hover {
        color: red !important;
        border-color: red !important;
    }

    /* ç‚¹å‡»åï¼ˆfocusæˆ–activeï¼‰é»˜è®¤ç°è‰²è¾¹æ¡† */
    button:focus, button:active {
        outline: none !important;
        box-shadow: none !important;
        color: inherit !important;
        border-color: #d3d3d3 !important;
        background-color: initial !important;
    }

    /* ä½†æ˜¯å¦‚æœæŒ‰é’®focusä¸”hoveræ—¶ï¼Œè¦†ç›–ä¸ºçº¢è‰²è¾¹æ¡† */
    button:focus:hover {
        color: red !important;
        border-color: red !important;
    }
    </style>
""", unsafe_allow_html=True)

st.write("æ¬¢è¿æ¥åˆ° Gemini Pro èŠå¤©æœºå™¨äººã€‚æ‚¨å¯ä»¥é€šè¿‡æä¾›æ‚¨çš„ Google API å¯†é’¥æ¥ç»§ç»­ã€‚")

# with st.expander("æä¾›æ‚¨çš„ Google API å¯†é’¥"):
#      google_api_key = st.text_input("Google API å¯†é’¥", key="", type="password")

# if not google_api_key:
#     st.info("è¯·è¾“å…¥ Google API å¯†é’¥ä»¥ç»§ç»­")
#     st.stop()

if "GEMINI_API_KEY" not in os.environ or not os.environ["GEMINI_API_KEY"]:
    print("æœªé…ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEYï¼Œè¯·å…ˆåœ¨.evnæ–‡ä»¶ä¸­é…ç½®ï¼")
else:
    print("GEMINI_API_KEY å·²é…ç½®ã€‚")

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

st.title("Gemini Pro ä¸ Streamlit èŠå¤©æœºå™¨äºº")


def clearHistory():
    st.session_state.messages.clear()
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ä½ å¥½ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å—ï¼Ÿ"}]
    print("èŠå¤©å†å²å·²æ¸…é™¤")


with st.sidebar:
    option = st.selectbox('é€‰æ‹©æ‚¨çš„æ¨¡å‹', ('gemini-2.0-flash', 'gemini-1.5-flash'))

    if 'model' not in st.session_state or st.session_state.model != option:
        st.session_state.chat = genai.GenerativeModel(
            option).start_chat(history=[])
        st.session_state.model = option

    st.write("åœ¨æ­¤å¤„è°ƒæ•´æ‚¨çš„å‚æ•°:")
    temperature = st.number_input(
        "æ¸©åº¦", min_value=0.0, max_value=1.0, value=0.5, step=0.01)
    max_token = st.number_input("æœ€å¤§è¾“å‡ºä»¤ç‰Œæ•°", min_value=0, value=10000)
    gen_config = genai.types.GenerationConfig(
        max_output_tokens=max_token, temperature=temperature)

    # st.divider()
    # st.markdown("""<span ><font size=1>ä¸æˆ‘è”ç³»</font></span>""", unsafe_allow_html=True)
    # "[å…¬ä¼—å·](https://mp.weixin.qq.com/s/VCQrnC6mQJUIWDxXGdutag)"
    # "[GitHub](https://github.com/mcks2000/LLM_Gemini_Pro_Streamlit)"

    st.divider()
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡ä»¶ï¼ˆPDF, TXT, DOCXï¼‰", type=['pdf', 'txt', 'docx'])
    upload_image = st.file_uploader(
        "åœ¨æ­¤ä¸Šä¼ æ‚¨çš„å›¾ç‰‡", accept_multiple_files=False, type=['jpg', 'png'])

    if upload_image:
        image = Image.open(upload_image)
    st.divider()

    if st.button("æ¸…é™¤èŠå¤©å†å²"):
        clearHistory()

# è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
file_text = ""
if uploaded_file:
    file_type = uploaded_file.type
    if file_type == "application/pdf":
        reader = PyPDF2.PdfReader(uploaded_file)
        file_text = "\n".join(page.extract_text()
                              for page in reader.pages if page.extract_text())
    elif file_type == "text/plain":
        stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        file_text = stringio.read()
    elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(uploaded_file)
        file_text = "\n".join([para.text for para in doc.paragraphs])
    else:
        st.warning("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ä½ å¥½ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å—ï¼Ÿ"}]


def markdown_to_docx_bytes(md_text):
    with tempfile.NamedTemporaryFile(suffix=".docx", delete=False) as tmpfile:
        tmp_path = tmpfile.name
    pypandoc.convert_text(md_text, 'docx', format='md', outputfile=tmp_path)
    with open(tmp_path, 'rb') as f:
        return f.read()


def summarize_for_filename(text: str, model_name="gemini-2.0-flash-lite") -> str:
    if not text:
        return "document"
    model = genai.GenerativeModel(model_name)
    prompt = (
        "è¯·å°†ä»¥ä¸‹å†…å®¹æ€»ç»“ä¸º5åˆ°10ä¸ªè¯ä»¥å†…çš„çŸ­è¯­ï¼Œç”¨äºæ–‡ä»¶åã€‚ä¸è¦åŠ æ ‡ç‚¹ï¼Œä¸è¦æ¢è¡Œï¼Œåªè¿”å›çŸ­è¯­ï¼š\n\n" + text[:1000]
    )
    try:
        response = model.generate_content(prompt)
        title = response.text.strip()
        # æ¸…ç†éæ³•æ–‡ä»¶åå­—ç¬¦
        title = re.sub(r'[\\/*?:"<>|]', '_', title)
        print(f"ç”Ÿæˆçš„æ–‡ä»¶åï¼š{title}")
        return title or "document"
    except Exception as e:
        print(f"ç”Ÿæˆæ–‡ä»¶åå‡ºé”™ï¼š{e}")
        return "document"


def safe_filename(name: str, default="doc.docx") -> str:
    # åªä¿ç•™å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿ï¼Œé˜²æ­¢æ–‡ä»¶åéæ³•
    safe_name = re.sub(r'[^\w\-_. ]', '', name)
    safe_name = safe_name.strip()
    if not safe_name:
        return default
    if not safe_name.lower().endswith(".docx"):
        safe_name += ".docx"
    return safe_name


def render_export_button(role, md_text: str, button_label="å¯¼å‡º", key=None):
    file_name = "doc.docx"
    if role == "assistant":
        messages = st.session_state.get("messages", {})
        # print(f"{key} message: {messages}")
        print()
        try:
            match = re.search(r'\d+', key)  # æå– key ä¸­çš„æ•°å­—éƒ¨åˆ†
            if match:
                if role == "assistant":
                    index = int(match.group()) - 1
                else:
                    index = int(match.group())
                print(f"index: {index}")
                if index >= 0 and index < len(messages):
                    content = messages[index].get("content", "")
                    print(f"content: {content}")
                    file_name = safe_filename(
                        content.split("\n", 1)[0])  # å–é¦–è¡Œä½œä¸ºæ–‡ä»¶å
                else:
                    print("ç´¢å¼•è¶Šç•Œ")
            else:
                print("key ä¸­ä¸åŒ…å«æ•°å­—")
        except (ValueError, IndexError, KeyError) as e:
            # ä»»ä½•å¼‚å¸¸éƒ½ç”¨é»˜è®¤æ–‡ä»¶å
            print(f"[å¯¼å‡ºå¼‚å¸¸] key={key}, é”™è¯¯: {e}")
            pass

    print(f"file_name: {file_name}")
    if st.download_button(
        label=button_label,
        data=markdown_to_docx_bytes(md_text),
        file_name=file_name,
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        key=key
    ):
        st.toast("å¯¼å‡ºæˆåŠŸï¼")


def copy(content):
    pyperclip.copy(content)


def retry(role, key, content):
    if role == "assistant":
        st.toast("ä»…ç”¨æˆ·æ¶ˆæ¯å¯é‡è¯•ã€‚")
        return
    print(f"é‡è¯•æŒ‰é’®ç‚¹å‡»ï¼Œretry_prompt: {content}")
    response = st.session_state.chat.send_message(
        content, stream=True, generation_config=gen_config)
    response.resolve()
    retry_msg = response.text
    messages = st.session_state.messages
    if key + 1 < len(messages):
        messages[key + 1]["content"] = retry_msg
    else:
        print({"role": "assistant", "content": retry_msg})


def render_btn(role, content: str, key: str):
    # æŒ‰é’®åŒºåŸŸ
    col1, col2, col3, col4, col5, col6, col7 = st.columns([1]*7)

    # å¯¼å‡ºæŒ‰é’®
    with col1:
        render_export_button(
            role, content, button_label="ğŸ“¥ å¯¼å‡º", key=f"export_{key}")

    # å¤åˆ¶æŒ‰é’®
    with col2:
        st.button("ğŸ“‹ å¤åˆ¶", key=f"copy_{key}", on_click=lambda: copy(content))

    # é‡è¯•æŒ‰é’®ï¼ˆä»…é™ assistant æ¶ˆæ¯ï¼‰
    with col3:
        # if role == "user":
        st.button("ğŸ”„ é‡è¯•", key=f"retry_{key}",
                  on_click=lambda: retry(role, key, content))

    # ç¼–è¾‘æŒ‰é’®
    with col4:
        # åˆå§‹åŒ–ç¼–è¾‘çŠ¶æ€
        if f"is_editing_{key}" not in st.session_state:
            st.session_state[f"is_editing_{key}"] = False

        if not st.session_state[f"is_editing_{key}"]:
            if st.button("âœï¸ ç¼–è¾‘", key=f"edit_{key}"):
                st.session_state[f"is_editing_{key}"] = True
                st.session_state[f"edit_input_{key}"] = content
                st.rerun()

    # åˆ é™¤æŒ‰é’®
    with col5:
        if st.button("âŒ åˆ é™¤", key=f"delete_{key}"):
            print(f"åˆ é™¤æŒ‰é’®ç‚¹å‡»ï¼Œkey1: {key}")
            if key == 0:
                st.toast("æç¤ºå¯¹è¯ï¼Œä¸å¯åˆ é™¤")
                return
            if "messages" in st.session_state:
                messages = st.session_state.messages
                if isinstance(messages, list) and 0 <= key < len(messages):
                    messages.pop(key)
                    st.rerun()
                else:
                    print(
                        f"æ— æ•ˆçš„ key: {key}, å½“å‰ messages é•¿åº¦: {len(messages)}")

    with col6:
        st.empty()

    with col7:
        st.empty()

    # æŠŠç¼–è¾‘æ¡†ç‹¬ç«‹æ”¾åœ¨åˆ—å¤–éƒ¨ï¼Œä½¿å…¶å æ•´è¡Œå®½åº¦
    if st.session_state.get(f"is_editing_{key}", False):
        # å æ•´è¡Œçš„å®½åº¦
        st.text_area(
            "ç¼–è¾‘å†…å®¹",
            key=f"edit_input_{key}",
            height=200
        )

        col_save, col_cancel, col3, col4, col5 = st.columns([1]*5)
        with col_save:
            if st.button("âœ… ä¿å­˜ä¿®æ”¹", key=f"save_edit_{key}"):
                st.session_state.messages[key][
                    "content"] = st.session_state[f"edit_input_{key}"]
                st.session_state[f"is_editing_{key}"] = False
                st.rerun()

        with col_cancel:
            if st.button("âŒ å–æ¶ˆ", key=f"cancel_edit_{key}"):
                st.session_state[f"is_editing_{key}"] = False
                st.rerun()

        with col3:
            st.empty()

        with col4:
            st.empty()

        with col5:
            st.empty()


# å±•ç¤ºèŠå¤©å†å²
for i, msg in enumerate(st.session_state.messages):
    content = msg["content"]
    role = msg["role"]
    st.chat_message(role).write(content)
    render_btn(role, content, i)

# å›¾ç‰‡ + æç¤ºè¾“å…¥
if upload_image:
    if option == "gemini-pro":
        st.info("è¯·åˆ‡æ¢åˆ° Gemini Pro Vision")
        st.stop()

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        render_btn("user", prompt, len(st.session_state.messages)-1)

        response = st.session_state.chat.send_message(
            [prompt, image], stream=True, generation_config=gen_config)
        response.resolve()
        msg = response.text

        st.session_state.chat = genai.GenerativeModel(
            option).start_chat(history=[])
        st.session_state.messages.append({"role": "assistant", "content": msg})

        st.image(image, width=300)
        st.chat_message("assistant").write(msg)
        render_btn("assistant", msg, len(st.session_state.messages)-1)

# æ–‡ä»¶ + æç¤ºè¾“å…¥
elif uploaded_file and file_text:
    if prompt := st.chat_input(placeholder="ä½ æƒ³é—®å…³äºä¸Šä¼ æ–‡ä»¶çš„ä»€ä¹ˆé—®é¢˜ï¼Ÿ"):
        combined_prompt = f"{prompt}\n\nä»¥ä¸‹æ˜¯ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ï¼š\n{file_text}"
        st.session_state.messages.append(
            {"role": "user", "content": combined_prompt})
        st.chat_message("user").write(prompt)
        render_btn("user", prompt, len(st.session_state.messages)-1)

        response = st.session_state.chat.send_message(
            combined_prompt, stream=True, generation_config=gen_config)
        response.resolve()

        msg = response.text
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)
        render_btn("assistant", msg, len(st.session_state.messages)-1)


# çº¯æ–‡æœ¬å¯¹è¯
else:
    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        render_btn("user", prompt, len(st.session_state.messages)-1)

        response = st.session_state.chat.send_message(
            prompt, stream=True, generation_config=gen_config)
        # print(f"ç»“æœ: {response}")
        response.resolve()
        msg = response.text
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)
        render_btn("assistant", msg, len(st.session_state.messages)-1)
