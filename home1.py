import streamlit as st
from PIL import Image
import google.generativeai as genai
import io
import docx
import PyPDF2
import markdown2
from docx import Document
from bs4 import BeautifulSoup
import pypandoc
import tempfile
from io import BytesIO
import base64
import streamlit.components.v1 as components
import re
import pyperclip


pypandoc.pandoc_path = r'C:\Users\Puture\AppData\Local\Pandoc\pandoc.exe'

st.set_page_config(page_title="Gemini Pro with Streamlit", page_icon="â™Š")

st.write("æ¬¢è¿æ¥åˆ° Gemini Pro èŠå¤©æœºå™¨äººã€‚æ‚¨å¯ä»¥é€šè¿‡æä¾›æ‚¨çš„ Google API å¯†é’¥æ¥ç»§ç»­ã€‚")

# with st.expander("æä¾›æ‚¨çš„ Google API å¯†é’¥"):
#      google_api_key = st.text_input("Google API å¯†é’¥", key="", type="password")

# if not google_api_key:
#     st.info("è¯·è¾“å…¥ Google API å¯†é’¥ä»¥ç»§ç»­")
#     st.stop()

genai.configure(api_key="")

st.title("Gemini Pro ä¸ Streamlit èŠå¤©æœºå™¨äºº")

with st.sidebar:
    option = st.selectbox('é€‰æ‹©æ‚¨çš„æ¨¡å‹', ('gemini-2.0-flash', 'gemini-1.5-flash'))

    if 'model' not in st.session_state or st.session_state.model != option:
        st.session_state.chat = genai.GenerativeModel(
            option).start_chat(history=[])
        st.session_state.model = option

    st.write("åœ¨æ­¤å¤„è°ƒæ•´æ‚¨çš„å‚æ•°:")
    temperature = st.number_input(
        "æ¸©åº¦", min_value=0.0, max_value=1.0, value=0.5, step=0.01)
    max_token = st.number_input("æœ€å¤§è¾“å‡ºä»¤ç‰Œæ•°", min_value=0, value=10000)
    gen_config = genai.types.GenerationConfig(
        max_output_tokens=max_token, temperature=temperature)

    # st.divider()
    # st.markdown("""<span ><font size=1>ä¸æˆ‘è”ç³»</font></span>""", unsafe_allow_html=True)
    # "[å…¬ä¼—å·](https://mp.weixin.qq.com/s/VCQrnC6mQJUIWDxXGdutag)"
    # "[GitHub](https://github.com/mcks2000/LLM_Gemini_Pro_Streamlit)"

    st.divider()
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡ä»¶ï¼ˆPDF, TXT, DOCXï¼‰", type=['pdf', 'txt', 'docx'])
    upload_image = st.file_uploader(
        "åœ¨æ­¤ä¸Šä¼ æ‚¨çš„å›¾ç‰‡", accept_multiple_files=False, type=['jpg', 'png'])

    if upload_image:
        image = Image.open(upload_image)
    st.divider()

    if st.button("æ¸…é™¤èŠå¤©å†å²"):
        st.session_state.messages.clear()
        st.session_state["messages"] = [
            {"role": "assistant", "content": "ä½ å¥½ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å—ï¼Ÿ"}]

# è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
file_text = ""
if uploaded_file:
    file_type = uploaded_file.type
    if file_type == "application/pdf":
        reader = PyPDF2.PdfReader(uploaded_file)
        file_text = "\n".join(page.extract_text()
                              for page in reader.pages if page.extract_text())
    elif file_type == "text/plain":
        stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        file_text = stringio.read()
    elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(uploaded_file)
        file_text = "\n".join([para.text for para in doc.paragraphs])
    else:
        st.warning("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ä½ å¥½ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å—ï¼Ÿ"}]


def markdown_to_docx_bytes(md_text):
    with tempfile.NamedTemporaryFile(suffix=".docx", delete=False) as tmpfile:
        tmp_path = tmpfile.name
    pypandoc.convert_text(md_text, 'docx', format='md', outputfile=tmp_path)
    with open(tmp_path, 'rb') as f:
        return f.read()


def summarize_for_filename(text: str, model_name="gemini-2.0-flash-lite") -> str:
    if not text:
        return "document"
    model = genai.GenerativeModel(model_name)
    prompt = (
        "è¯·å°†ä»¥ä¸‹å†…å®¹æ€»ç»“ä¸º5åˆ°10ä¸ªè¯ä»¥å†…çš„çŸ­è¯­ï¼Œç”¨äºæ–‡ä»¶åã€‚ä¸è¦åŠ æ ‡ç‚¹ï¼Œä¸è¦æ¢è¡Œï¼Œåªè¿”å›çŸ­è¯­ï¼š\n\n" + text[:1000]
    )
    try:
        response = model.generate_content(prompt)
        title = response.text.strip()
        # æ¸…ç†éæ³•æ–‡ä»¶åå­—ç¬¦
        title = re.sub(r'[\\/*?:"<>|]', '_', title)
        print(f"ç”Ÿæˆçš„æ–‡ä»¶åï¼š{title}")
        return title or "document"
    except Exception as e:
        print(f"ç”Ÿæˆæ–‡ä»¶åå‡ºé”™ï¼š{e}")
        return "document"


def render_export_button(md_text: str, button_label="å¯¼å‡º", file_name=None, key=None):
    if st.download_button(
        label=button_label,
        data=markdown_to_docx_bytes(md_text),
        file_name="doc.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        key=key
    ):
        st.toast("å¯¼å‡ºæˆåŠŸï¼")


def copy(content):
    pyperclip.copy(content)


def retry(role, key, content):
    if role == "assistant":
        st.toast("ä»…ç”¨æˆ·æ¶ˆæ¯å¯é‡è¯•ã€‚")
        return
    retry_prompt = st.session_state.messages[key]["content"] if key >= 0 else ""
    print(f"é‡è¯•æŒ‰é’®ç‚¹å‡»ï¼Œretry_prompt: {retry_prompt}")
    response = st.session_state.chat.send_message(
        retry_prompt, stream=True, generation_config=gen_config)
    response.resolve()
    retry_msg = response.text
    st.session_state.messages[key + 1]["content"] = retry_msg
    # st.rerun()


def render_btn(role, content: str, key: str):
    # æŒ‰é’®åŒºåŸŸ
    col1, col2, col3, col4, col5, col6, col7 = st.columns([1]*7)

    # å¯¼å‡ºæŒ‰é’®
    with col1:
        render_export_button(content, button_label="ğŸ“¥ å¯¼å‡º", key=f"export_{key}")

    # å¤åˆ¶æŒ‰é’®
    with col2:
        st.button("ğŸ“‹ å¤åˆ¶", key=f"copy_{key}", on_click=lambda: copy(content))

    # é‡è¯•æŒ‰é’®ï¼ˆä»…é™ assistant æ¶ˆæ¯ï¼‰
    with col3:
        st.button("ğŸ”„ é‡è¯•", key=f"retry_{key}",
                  on_click=lambda: retry(role, key, content))

    # ç¼–è¾‘æŒ‰é’®
    with col4:
        if st.button("âœï¸ ç¼–è¾‘", key=f"edit_{key}"):
            new_text = st.text_area(
                "ç¼–è¾‘å†…å®¹", value=content, key=f"edit_input_{key}")
            if st.button("âœ… ä¿å­˜ä¿®æ”¹", key=f"save_edit_{key}"):
                print(f"ä¿å­˜ä¿®æ”¹æŒ‰é’®ç‚¹å‡»ï¼Œnew_text: {new_text}")
                st.session_state.messages[key]["content"] = new_text
                st.rerun()

    # åˆ é™¤æŒ‰é’®
    with col5:
        if st.button("âŒ åˆ é™¤", key=f"delete_{key}"):
            print(f"åˆ é™¤æŒ‰é’®ç‚¹å‡»ï¼Œkey1: {key}")
            st.session_state.messages.pop(key)
            st.rerun()


# å±•ç¤ºèŠå¤©å†å²
for i, msg in enumerate(st.session_state.messages):
    content = msg["content"]
    role = msg["role"]
    st.chat_message(role).write(content)
    render_btn(role, content, i)

# å›¾ç‰‡ + æç¤ºè¾“å…¥
if upload_image:
    if option == "gemini-pro":
        st.info("è¯·åˆ‡æ¢åˆ° Gemini Pro Vision")
        st.stop()

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        render_btn("user", prompt, len(st.session_state.messages)-1)

        response = st.session_state.chat.send_message(
            [prompt, image], stream=True, generation_config=gen_config)
        response.resolve()
        msg = response.text

        st.session_state.chat = genai.GenerativeModel(
            option).start_chat(history=[])
        st.session_state.messages.append({"role": "assistant", "content": msg})

        st.image(image, width=300)
        st.chat_message("assistant").write(msg)
        render_btn("assistant", msg, len(st.session_state.messages)-1)

# æ–‡ä»¶ + æç¤ºè¾“å…¥
elif uploaded_file and file_text:
    if prompt := st.chat_input(placeholder="ä½ æƒ³é—®å…³äºä¸Šä¼ æ–‡ä»¶çš„ä»€ä¹ˆé—®é¢˜ï¼Ÿ"):
        combined_prompt = f"{prompt}\n\nä»¥ä¸‹æ˜¯ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ï¼š\n{file_text}"
        st.session_state.messages.append(
            {"role": "user", "content": combined_prompt})
        st.chat_message("user").write(prompt)
        render_btn("user", prompt, len(st.session_state.messages)-1)

        response = st.session_state.chat.send_message(
            combined_prompt, stream=True, generation_config=gen_config)
        response.resolve()
        msg = response.text
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)
        render_btn("assistant", msg, len(st.session_state.messages)-1)


# çº¯æ–‡æœ¬å¯¹è¯
else:
    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        render_btn("user", prompt, len(st.session_state.messages)-1)

        response = st.session_state.chat.send_message(
            prompt, stream=True, generation_config=gen_config)
        response.resolve()
        msg = response.text
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)
        render_btn("assistant", msg, len(st.session_state.messages)-1)
